# 面试问题
## 实现一个无锁队列
   
    ```c++
    去头
    1. 取出dummyHead
    2. cas将dummyHead后移一位，即比较dummyHead是否为第一步的值，若是则删除成功，如果不是删除失败，跳转到第一步。
    加尾
    1. 取出tail
    2. tail的next结点应该为nullptr，根据这个值进行CAS换成应该添加的结点，如果比较操作时发现tail的next指针已经不是nullptr了则跳转到上一步循环操作。
    ```
   无锁队列的实现需要采用lock-free设计，用操作系统提供的原子操作，进行CAS(compare and swap)。在我的项目中，
   没有采用无锁队列，主要因为以下两点：

  1. 首先是基本上用不到，我采用的one loop per thread设计方法，每个I/O线程只会处理自己的数据结构，如果在其他线程中调用了相关函数，
   会转发给对应的I/O线程，因此每个队列只有唯一一个线程访问，无需加锁。
  2. 加锁的队列我应该只使用在了异步日志中，后端日志线程需要取出前端日志线程写的链表，需要加锁，但是在我实现中，临界区很小，都采用的c++11的
   移动语义，只有常数级别的操作时间，而且我的日志系统经过测试是完全满足性能需求的。

## epoll源码和poll源码
  
  epoll_create()会初始化就绪链表rdlist,文件描述符对应的红黑树头节点root。

  epoll_ctl()就直接往对应的红黑树插入或修改对应的结点。并注册对应的回调事件，一但事件发生就会执行回调函数，内核会将就绪事件插入就绪队列rdlist.

  epoll_wait()简单返回就绪链表的事件，并且清空就绪链表。

  LT和ET的区别只是一个if语句，ET边缘触发是放入就绪链表时会检查状态是否改变，如果没有改变则不会放入就绪链表。

  poll是将用户的pollfd数组全部从用户空间拷贝到内核空间，执行poll时内核会通过轮询的方式检查文件描述符的事件，一旦发生，又会将整个数组从内核拷贝到用户空间，所以拷贝开销很大。

  并且用户还需要依个检查返回的pollfd。

## 服务器平滑升级

  参考Nginx的平滑升级，老服务器继续处理之前的事件但是拒绝接受新连接。升级的服务器处理新的连接，老服务器处理完所有连接后关闭服务器。

## 怎么检查内存泄漏？

  首先只有遵守RAII，坚持使用智能指针，就基本不会有内存泄漏的风险。在C/C++语言中没有完美的检查内存泄露的办法，就连Nginx都会时不时爆出内存泄露问题，可能检查的方法之一是时刻关注服务器的内存使用量，看是不是随着时间的不断推移内存不断增加，如果是的应该就产生了内存泄露。产生了内存泄露后，如果使用了智能指针，检查下有没有循环引用，如果用原始指针，检查一下堆的申请后有没有释放。

## 如果解决死锁

  首先讲讲写多线程程序时如果预防死锁，拿我的这个项目来说，因为one loop per thread，检查是否完全遵循了这个原则，就是I/O线程只处理自己的工作。

  再者，尽量不要让锁出了函数scope，这是大多数死锁的来源，然后考虑业务逻辑是否需要那么多锁，因为死锁都是两个以上的锁导致的。加锁一定要按自己定义的顺序加。我推荐用不可重入的互斥锁代替可重入的递归锁，因为互斥锁寻找问题逻辑清晰很多。

  当然，有的时候我们粗心大意可能会没有遵守一些法则，出现了死锁。我是先详细看日志，只要日志写的够详细，能够大幅度的缩小你的检查范围，然后去看代码，还是看不出来的话，可以考虑将线程调用栈bt打开(abort(),core文件)，看看函数调用栈卡在了什么位置，基本上这时候都能发现为什么死锁了。

## 为什么不用内存池

  1. 没有必要，举个杀死比赛的论点，当今的stl的空间配置器已经是简单的new的delete了，若干年前可能还出现过SGI版本的内存配置器，但现在也不用了，连STL都不用内存池，肯定有十足的理由。
  2. 之所以stl也不用了，是因为现在的malloc和free已经优化的相当好了,libc的malloc实际上内部已经实现了内存池。
  3. 就算用内存池，在多线程程序下怎么加锁，难道对整个内存池加锁吗，当然肯定有方法，不过实现起来应该也很麻烦，效率也堪忧，况且智能指针提供的RAII机制也和内存池不搭配。


## Irono与一般框架的区别(特点)；为什么不用虚函数？面向对象与基于对象？
  
  > 背诵书上449页
    
面向对象为封装继承多态，基于对象只用了封装，两者编程思想具有本质上的区别。

在C++中，我对继承和多态是比较抵制的，**宽泛的说**因为它很难纠正错误.如果有一棵类型继承树，人们在一开始设计时就得考虑各个class在树上的位置。随着时间的推移，原来正确的决定有可能变成错的。
但是更正这个错误的成本很高。要想把这个class在继承树上从一个节点挪到另一个节点，可能要触及所有用到了这个class的客户代码，所有用到其各层基类的客户代码，以及从这个class派生出来的全部类的代码。
简直是牵一发而动全身，在C++缺乏良好的重构工具的语言下，很多时候错误只能保留，用一些别的手法去掩盖整个架构的问题。久而久之，代码架构越来越烂，最后只好推倒重来。

用继承树这种方法建模，也是几十年前的流行思想了，现在也越来越被证实不符合真实世界。事物是变化的，我们直到，继承是强烈耦合的is-a的关系，B继承A就是B is A。但是随着时间推移，可能B is more like C，
那你怎么办，改代码代价太高。我们看看现代编程语言Go的无继承体系，一个object实现了某种operations，就能当做某种东西来用，不需要显式地继承或实现某种结构，这就是一种时代的进步。

当然，前面说的都比较宽泛，拿我的项目的具体来说。Irono是一个现代的 C++ 服务器框架库。现代和古代的API区别在于两方面。一个是事件回调，另外一个是资源管理。一般的网络库设计API的方式是定义一个接口（抽象基类），包含几种网 络事件对应的处理函数。你的代码去继承这个接口，这个接口会定义收到消息是回调哪个虚函数，然后你覆盖一下这个虚函数。然后把你的对象注册到网络库中，发 生事件的时候就回调你的虚函数。一般的 Framework 都这么搞，这就是传统的或者说古代的 C++ 网络库的做法，也是Java网络库的做法。这种做法在C++中面临的一个直接问题是对象的生命期管理，因为C++的动态绑定只能通过指针和引用来实现，你 必须把基类指针传给framework，才能获得事件回调。那么这个派生类对象何时销毁就成了难点，它的所有权到底归谁？有的网络库甚至在事件处理函数中 出现了delete this;这种代码，实在让人捏一把汗。C++不像Java有垃圾回收，用户不需要操心对象的生命期，这也是本质的区别。

我现在的回调方式是用function/bind。function不对类型和函数名做限制，只对参数和返回类型做部分限制。如果你通过传统的继承来回调的话，你这个类型必须是 framework里某个基类的派生类，函数的名字必须一样，参数列表必须一样，返回类型也基本肯定是一样。但是function没有这些 限制。Irono框架不是一个面向对象(object-oriented)的库，它是一个基于对象(object-based)的库。它在接口上没有表 现出继承的特性，它用的是function的注册/回调机制，网络事件的表示就用function。所以对Irono来讲，它不需要知道你写什么类，也不强迫继承，更不需要知道你的函数叫什么名字，你给它的就是一个function对象，限制就很少。而且你没有把对象指针传给Irono框架，那么就可以按原有的方式管理对象的生命期。

还有一个优势就是资源管理，Irono在一处最关键的地方也使用了引用计数（Reference Counting）型智能指针，用的是标准库的shared_ptr。我在表示 TCP 连接的class上使用了引用计数，是因为TCP连接是短命对象(short-lived)。但是当连接被动断开的时候，网络库不能立刻销毁对象，因为用户可能还持有它的引用,甚至还在该对象的内部函数中，准备用来发消息。如果直接delete，有可能造成空悬指针,更可能造成对象生命期异常。因此既然TCP对象是Irono和用户代码共同拥有，那就用引用计数好了。我的框架可以确保你的连接生存能够到正确析构对象，用户也可以持有这个连接延长它的生命期。还句话说，用Irono你就不用担心指针失 效的问题，可以避免一些古老的 C++ 程序中的一些内存错误。
这种用对象来封装文件描述符等系统资源的做法是C++独有的资源管理方式，称为RAII。

通过把文件描述符的生命期与对象等同起来，我们还能有效地避免串 话(cross talk)。比如说，操作系统给你一个新的TCP连接，文件描述符就是一个小整数，这个整数可能等于刚刚关闭的某个TCP连接的文件描述符。比如你现在有 一个连接号是3，你把连接关了再打开有可能还是3，所以就带来连接管理方面的一些麻烦。如果你是用 C 写，不小心的话就会造成你这里关了3这个连接，但是程序其他地方还在往3这个连接发消息（考虑多线程的话更头疼），但其实3这个连接已经指向其他地方了， 就跟使用野指针一样。用RAII就没有这个困扰，因为3这个连接的生命期和对象绑定，对象活着，连接就不会关闭，也就不会有其他对象同时使用了3这个文件描述符。

## 为什么不使用递归锁或者读写锁
  
首先我个人是坚持使用非递归的互斥器的。

首选非递归mutex，绝不是为了性能，单说性能两者基本没有差距，递归锁最多比非递归锁多用了一个计数器。在同一个线程中多次对非递归mutex加锁会立刻导致死锁，我认为这是它的优点，能帮助我们思考对锁的需求，更早的发现问题。

毫无疑问，递归锁用起来更方便，因为一个线程不会将自己锁死了。正因为它方便，递归锁可能会隐藏代码的一些问题，典型情况就是你以为拿到一个锁就能修改对象了，却没想到外层代码已经拿到了锁，正在修改同一个对象。

陈硕在博客中也写过，它工作这么多年没有遇到过必须要递归锁的情况，Pthreads的权威专家David 也写过这样一句话：一个有效率的可靠的多线程编码有一个最基本的原则，就是follow your design，一个正确的和容易理解的设计是不需要递归锁的。

然后我讲讲一些典型情况，比如读写锁，完全可以用智能指针实现copy-on-write，效率比读写锁更高，适用性也更好。

## false sharing 伪共享
  
  多个CPU读写同一个缓存行而导致位于cache L1、L2的缓冲失效，必须去内存或者cache L3取，大大损失
  了性能

## 最大的难点与解决

Tcp连接对象的创建过程，创建地点和实际拥有者的矛盾，框架需要提供的功能和Tcp连接实际管理者的矛盾。见临时笔记`TcpServer类`。

Tcp连接对象的销毁，或者说Tcp连接对象正确的生命期管理，不能销毁太早也不能去意外延长它的生命期导致占用内存和文件描述符。
比如，一次epoll循环中，read到0，即对面关闭套接字了，那么此时你就该销毁Tcp连接对象。但这里面有很多问题很多细节和难点。
1. 你read返回0时，你在Tcp连接对象的内部，即Tcp连接对象拥有的事件句柄检测到了关闭事件，你在其中回调了销毁连接函数，然后你在自己内部对象的函数中调用了你自己的析构函数，十分危险，因此需要一种延后销毁机制
2. Tcp连接对象需要清理的东西不只有你自己I/O线程的资源，在外层的主Reator的Tcp服务器对象拥有全部的Tcp连接对象的哈希表，用于统筹，所以你还需要清理别人的I/O线程的资源，这涉及到跨线程清理
3. 我发现就算实现了跨线程清理主I/O线程的资源，也会提前死亡，造成危险的线程不安全问题，因为外层清理自己的Tcp连接对象的shared_ptr时，它是最后一个，你擦除了它，它就直接自动在外层I/O线程执行Tcp连接对象的析构函数了，但根据one loop per thread这种架构的本质，就是应该任何的资源都应该在属于自己的I/O线程中操作，特别是析构这种行为，你不应该暴露给其他线程，应该在对象本身的线程中销毁。

**解决方法：**
1. 回调队列，runInLoop与发送
2. shared_from_this, bind等构造临时智能指针，这样就可以保证最后一步销毁时还有一个临时的智能指针绑定者资源，不会提前析构，然后因为临时，也不会意外延长生命期。
   
## Reactor模式

非阻塞I/O + I/O复用，程序的基本结构是一个事件循环，以事件驱动和事件回调的方式实现业务逻辑。在网络编程中有很多是事务性的工作，可以提取为公用的框架或库，而用户只需要填上关键的业务逻辑代码，并将回调函数注册到框架中，就可以实现完整的网络服务，这正是Reactor模式的主要思想。

**本质缺点**: 要求事件回调函数必须是非阻塞的。对于涉及网络IO的请求响应式协议，容易割裂业务逻辑，使其散布于多个回调函数中，相对不容易理解和维护。

### 与Redis6.0的设计方案的取舍

和我irono不同，不是主Reactor和多个从Reactor结构。我的irono会将整个连接对象分发给从I/O线程，接着整个连接的所有事件处理包括I/O包括业务逻辑都在从I/O线程中做，主Reactor只负责监听和分发Tcp连接对象。

而Redis的实现很有趣，在redis6.0之前，如果遇到某个套接字可读或可写事件，它会直接对其进行处理，比如直接read或write它，当然write有些差别，是先放到输出缓冲区然后Redis会在进入eventloop之前对其遍历处理。

但在Redis6.0中，主线程碰到Tcp连接可读事件，并调用读回调函数时，它回调函数里修改了逻辑，它会在满足一些条件时，将这个读事件处理推迟，将这个读事件放入一个全局变量-链表中，相当于对事件循环执行过程中，会将所有读写事件实际I/O推迟，放到读和写两个待执行事件链表中。

然后主线程在进入下一次事件循环前，同样也会执行一个叫做beforeSleep的回调函数，此函数会执行分发操作，将刚才放到链表里的事件用round-robin的方法均匀的分发给I/O线程中，当然主线程也会分到一部分，接着所有线程开始处理分发到的I/O任务，主线程处理完后会等待I/O线程处理完毕，源码的检查方法是遍历每一个I/O线程的任务链表累计数量，当累计和为0就表示所有I/O线程都处理完了，接着主线程会对所有的处理完I/O的事件进行处理，比如执行对应的命令，所以Redis的多线程实际上只有主线程会执行命令，I/O线程只负责I/O任务或者命令的解析，实际命令执行还是在主线程中做。

Redis多线程也是一种多I/O线程的实现思路，即它实际分发的是客户端的I/O事件，而我分发的是连接，为什么我不采取Redis的手法呢？因为场景不同，首先Redis的命令的执行全部主线程中，因为执行命令无需加锁，所以它为了满足这个无锁执行命令的需求才采取了这样一种比较复杂的策略，而我没有这样的负担，而且很显然我的处理在分发完Tcp连接后，主Reactor和从Reactor基本就没有联系了，耦合性更低性能也更好，而且我从I/O线程也能执行对应的读写逻辑，因此可以同时处理多个Tcp连接的用户回调函数，而Redis这种设计不行，当然Redis这样设计也是因为自己的需求，毕竟一切的设计都是基于需求。

而且多reactor的方法是全并行的，各个eventloop只需要管理自己的连接事件或者说文件描述符，各个reactor处理自己的成员。但Redis这种本质上不是完全并行的，而是串行和并行都使用了，比如主线程需要收集所有的I/O读写事件放入对应的链表中，然后在主线程中进行round-robin分发任务，最后在所有I/O线程处理完I/O事件后也只有主线程执行命令，这段时间里其实只有主线程在工作，而从I/O线程都在睡眠，所以它并不是全并行的，性能也不及多Reactor的方案能达到全并行。
## one loop per thread

**优点：**

1.   线程数目基本固定，可以在程序启动时设置，不会频繁的创建和销毁
2.   可以很方便地在线程间调配负载。
3.   IO事件发生的线程是固定的，同一个TCP连接不用考虑事件并发。
4.   让线程之间的并发通信开销显著降低，每个I/O线程只需要处理自己的事件，若要向别的I/O线程中塞东西，可以用统一的方法实现，比如 `runInLoop`发送过去。

主I/O线程代表着事件的主循环，需要让哪个从I/O线程干活，就把对应的timer或则I/O事件如TCP连接注册到对应线程的loop里面即可。比如对实时性有要求的连接可以单独用一个I/O线程，对于数据量大的可以用一个I/O线程，并将计算事件分摊到计算线程池里。换句话说，能够实现TCP连接优先级调度。


## 优雅的关闭连接

shutdown会保证输出缓冲区的数据全部发送完后才走四次挥手，而close默认情况下都会直接丢弃发送缓冲区。

close：如果接受缓冲区还有数据，则直接发送RST。若没数据正常走四次挥手，若在FIN_WAIT2待太久会强制关闭套接字，若此时还收到了新数据，会发送RST并关闭套接字。

因为**irono**需要保证用户调用send发送的数据正常情况下一定会发送给对方，即只提供了封装的shutdown函数，使用框架的用户调用`send()`后直接调用`shutdown()`是安全的，框架会保证用户层的输出缓冲区全部`write()`到内核输出缓冲区后才调用linux的`shutdown()`函数。

## 栈上缓冲区处理read()

首先redis源码也是水平触发，以确保各个连接的公平性。

redis源码是16KB的扩容输入缓冲区buffer，并且每一次read()最多读16KB数据，而且如果读不到16KB还会出现内存空闲，导致内部碎片，若需要读的数据过多会触发多次系统调用和sds的多次内存创建和析构

而我采用栈上缓冲区64KB空间，用readv()函数读到我定义的输入缓冲区ector buffer中和栈上缓冲区64KB中，然后根据返回值知道到底读了多少，就可以根据返回值对vector进行精确扩容，不但减少了缓冲区销毁和创建的次数，减少了开销，并且一次能读的数据也比redis 16KB大四倍，还没有内存碎片。

## 网络编程的本质

三个半事件：

1. 连接的建立 accept新连接
2. 连接的断开，包括主动断开(`close、shutdown`)和被动断开(`read()`返回0)
3. 消息到达，文件描述符可读。 最重要的一个事件
4. 消息发送完毕，指将消息写入操作系统的缓冲区。算半个事件。

## 不足之处

 1. 优化的还不够，多线程吞吐量进步不多
 2. 高水位回调现在只是简单的丢弃缓冲区
 3. 没有实现I/O线程的优先级调度
   
# 复习路线

**背书 + 回顾文档 + 重看源码逻辑**